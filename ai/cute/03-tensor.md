## Tensor
This chapter is about `Tensor`, it comprises two parts: `Layout` and `Engine`.

The `Layout` is what we discussed in previous chapter, it maps a *coordinate* to an *index*.

The `Engine` is a random-access iterator, which may contain some data like base pointer, data type and etc.

### Tensor creation
There are two types of `Tensor`
1. Owning `Tensor`, it means the `Tensor` take the ownership of the address space which it point to. When you copy the Tensor, you (deep-)copy its elements, and the Tensor's destructor deallocates the array of elements.
2. Nonowning `Tensor`, it just take the base pointer of the address space as its parameter. Copying the Tensor doesn't copy the elements, and destroying the Tensor doesn't deallocate the array of elements.

What we usually used is the Nonowning `Tensor` in CUTE.

### Cases
#### Owning Tensor
For Owning `Tensor`, we don't need to explictly pass an address to space to it, just like:

```
// Register memory (static layouts only)
Tensor rmem_4x8_col = make_tensor<float>(Shape<_4,_8>{});
Tensor rmem_4x8_row = make_tensor<float>(Shape<_4,_8>{},
                                         LayoutRight{});
Tensor rmem_4x8_pad = make_tensor<float>(Shape <_4, _8>{},
                                         Stride<_32,_2>{});
Tensor rmem_4x8_like = make_tensor_like(rmem_4x8_pad);
```

We just need to pass the data type and `Layout`, then CUTE will help us create the `Tensor`.

If we print them:

```
rmem_4x8_col  : ptr[32b](0x7fff48929460) o (_4,_8):(_1,_4)
rmem_4x8_row  : ptr[32b](0x7fff489294e0) o (_4,_8):(_8,_1)
rmem_4x8_pad  : ptr[32b](0x7fff489295e0) o (_4,_8):(_32,_2)
rmem_4x8_like : ptr[32b](0x7fff48929560) o (_4,_8):(_8,_1)
```

We could see all the tensors have **different** address.

#### Nonowning Tensor

For Nonowning `Tensor`, we should explictly pass an address/point to it, just like:

```
float* A = ...;

// Untagged pointers
Tensor tensor_8   = make_tensor(A, make_layout(Int<8>{}));  // Construct with Layout
Tensor tensor_8s  = make_tensor(A, Int<8>{});               // Construct with Shape
Tensor tensor_8d2 = make_tensor(A, 8, 2);                   // Construct with Shape and Stride

// Global memory (static or dynamic layouts)
Tensor gmem_8s     = make_tensor(make_gmem_ptr(A), Int<8>{});
Tensor gmem_8d     = make_tensor(make_gmem_ptr(A), 8);
Tensor gmem_8sx16d = make_tensor(make_gmem_ptr(A), make_shape(Int<8>{},16));
Tensor gmem_8dx16s = make_tensor(make_gmem_ptr(A), make_shape (      8  ,Int<16>{}),
                                                   make_stride(Int<16>{},Int< 1>{}));

// Shared memory (static or dynamic layouts)
Layout smem_layout = make_layout(make_shape(Int<4>{},Int<8>{}));
__shared__ float smem[decltype(cosize(smem_layout))::value];   // (static-only allocation)
Tensor smem_4x8_col = make_tensor(make_smem_ptr(smem), smem_layout);
Tensor smem_4x8_row = make_tensor(make_smem_ptr(smem), shape(smem_layout), LayoutRight{});
```

We could print them:

```
tensor_8     : ptr[32b](0x7f42efc00000) o _8:_1
tensor_8s    : ptr[32b](0x7f42efc00000) o _8:_1
tensor_8d2   : ptr[32b](0x7f42efc00000) o 8:2
gmem_8s      : gmem_ptr[32b](0x7f42efc00000) o _8:_1
gmem_8d      : gmem_ptr[32b](0x7f42efc00000) o 8:_1
gmem_8sx16d  : gmem_ptr[32b](0x7f42efc00000) o (_8,16):(_1,_8)
gmem_8dx16s  : gmem_ptr[32b](0x7f42efc00000) o (8,_16):(_16,_1)
smem_4x8_col : smem_ptr[32b](0x7f4316000000) o (_4,_8):(_1,_4)
smem_4x8_row : smem_ptr[32b](0x7f4316000000) o (_4,_8):(_8,_1)
```

It seems all of them share a same address.


### Tiling a Tensor

We could use similar method for `Layout` to tile a `Tensor`, just like:

```
   composition(Tensor, Tiler)
logical_divide(Tensor, Tiler)
 zipped_divide(Tensor, Tiler)
  tiled_divide(Tensor, Tiler)
   flat_divide(Tensor, Tiler)
```

### Slicing a Tensor
We could slice a Tensor with `_` (an instance of `cute::Underscore`), it just same as `:` in `pytorch`, let's see some examples:

```
// ((_3,2),(2,_5,_2)):((4,1),(_2,13,100))
Tensor A = make_tensor(ptr, make_shape (make_shape (Int<3>{},2), make_shape (       2,Int<5>{},Int<2>{})),
                            make_stride(make_stride(       4,1), make_stride(Int<2>{},      13,     100)));

// ((2,_5,_2)):((_2,13,100))
Tensor B = A(2,_);

// ((_3,_2)):((4,1))
Tensor C = A(_,5);

// (_3,2):(4,1)
Tensor D = A(make_coord(_,_),5);

// (_3,_5):(4,13)
Tensor E = A(make_coord(_,1),make_coord(0,_,1));

// (2,2,_2):(1,_2,100)
Tensor F = A(make_coord(2,_),make_coord(_,3,_));
```

We could illustrate them as:

![Slicing a Tensor](./pic/03-tensor-slicing.png)

From the above figure we have two observations:
1. The slicing will also change the base pointer for the `Tensor`, like for the first case `B=A(2,_)`, we could see it move the base pointer from `0` to `8` (first elements in gray).
2. Dimesion for with coordinate as specific value will be keep, with `_` will keep all coordinate in this dim.